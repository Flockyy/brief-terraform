# ğŸš• NYC Taxi Data Pipeline - Infrastructure as Code

[![Terraform](https://img.shields.io/badge/Terraform-1.6.0-623CE4?logo=terraform)](https://www.terraform.io/)
[![Azure](https://img.shields.io/badge/Azure-Cloud-0078D4?logo=microsoft-azure)](https://azure.microsoft.com/)
[![Docker](https://img.shields.io/badge/Docker-Container-2496ED?logo=docker)](https://www.docker.com/)
[![Python](https://img.shields.io/badge/Python-3.11-3776AB?logo=python)](https://www.python.org/)

> Infrastructure as Code pour dÃ©ployer un pipeline de donnÃ©es automatisÃ© sur Azure, traitant les donnÃ©es des taxis de New York (NYC TLC Trip Record Data)

## ğŸ“‹ Vue d'Ensemble

Ce projet implÃ©mente une **infrastructure cloud complÃ¨te** sur Azure pour ingÃ©rer, transformer et analyser les donnÃ©es historiques des taxis new-yorkais. L'infrastructure est entiÃ¨rement provisionnÃ©e avec **Terraform**, permettant un dÃ©ploiement reproductible et versionnÃ©.

### ğŸ¯ Objectifs du Projet

- **Infrastructure as Code** : Provisionnement automatisÃ© avec Terraform
- **Data Pipeline AutomatisÃ©** : TÃ©lÃ©chargement, transformation et chargement des donnÃ©es
- **Architecture Cloud-Native** : Containerisation avec Docker et Azure Container Apps
- **Monitoring** : Logs centralisÃ©s avec Azure Log Analytics
- **CI/CD** : Workflows GitHub Actions pour le dÃ©ploiement automatique

### ğŸ“Š Pipeline de DonnÃ©es

Le pipeline traite les donnÃ©es en 3 Ã©tapes :

1. **Download** : TÃ©lÃ©charge les fichiers Parquet depuis NYC TLC (3 mois de donnÃ©es ~153 MB)
2. **Load** : Charge les donnÃ©es dans PostgreSQL via DuckDB avec filtres de qualitÃ©
3. **Transform** : CrÃ©e un modÃ¨le en Ã©toile (star schema) avec tables de dimensions et de faits

## ğŸ—ï¸ Architecture DÃ©ployÃ©e

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          AZURE CLOUD                                  â”‚
â”‚                                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  ğŸ”„ CONTAINER APPS ENVIRONMENT                                 â”‚  â”‚
â”‚  â”‚                                                                 â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚
â”‚  â”‚  â”‚  NYC Taxi Pipeline Container App                         â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  ğŸ“¥ Pipeline 1: Download                           â”‚  â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  â†’ TÃ©lÃ©charge 3 fichiers Parquet (153 MB)         â”‚  â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  â†’ Upload vers Azure Blob Storage                 â”‚  â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  ğŸ’¾ Pipeline 2: Load to PostgreSQL                 â”‚  â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  â†’ Lecture depuis Blob Storage                     â”‚  â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  â†’ Chargement avec DuckDB                          â”‚  â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  âš™ï¸ Pipeline 3: Transform (Star Schema)            â”‚  â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  â†’ CrÃ©ation des tables de dimensions               â”‚  â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  â†’ CrÃ©ation de la table de faits                   â”‚  â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  ğŸ“¦ STORAGE     â”‚         â”‚  ğŸ—„ï¸ DATA WAREHOUSE               â”‚   â”‚
â”‚  â”‚                 â”‚         â”‚                                   â”‚   â”‚
â”‚  â”‚  Azure Blob     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  Cosmos DB for PostgreSQL        â”‚   â”‚
â”‚  â”‚  Storage        â”‚         â”‚  (Citus Distributed)              â”‚   â”‚
â”‚  â”‚                 â”‚         â”‚                                   â”‚   â”‚
â”‚  â”‚  âœ… raw/        â”‚         â”‚  ğŸ“‹ Tables:                       â”‚   â”‚
â”‚  â”‚  âœ… processed/  â”‚         â”‚   â”œâ”€ staging_taxi_trips           â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚   â”œâ”€ dim_datetime                 â”‚   â”‚
â”‚                               â”‚   â”œâ”€ dim_location                 â”‚   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚   â”œâ”€ dim_payment                  â”‚   â”‚
â”‚  â”‚  ğŸ³ REGISTRY    â”‚         â”‚   â”œâ”€ dim_vendor                   â”‚   â”‚
â”‚  â”‚                 â”‚         â”‚   â””â”€ fact_trips                   â”‚   â”‚
â”‚  â”‚  Azure Containerâ”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”‚  Registry       â”‚                                                 â”‚
â”‚  â”‚                 â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  ğŸ“¦ Image:      â”‚         â”‚  ğŸ“Š MONITORING                    â”‚   â”‚
â”‚  â”‚  nyc-taxi-      â”‚         â”‚                                   â”‚   â”‚
â”‚  â”‚  pipeline:      â”‚         â”‚  Log Analytics Workspace          â”‚   â”‚
â”‚  â”‚  latest         â”‚         â”‚  âœ… Application logs               â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚  âœ… System metrics                 â”‚   â”‚
â”‚                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ“¦ Ressources Azure DÃ©ployÃ©es

| Ressource | Type | Description | CoÃ»t estimÃ© |
|-----------|------|-------------|-------------|
| **Storage Account** | Standard LRS | Stockage des fichiers Parquet | ~0.02â‚¬/mois |
| **Container Registry** | Basic | Registry privÃ© pour l'image Docker | ~5â‚¬/mois |
| **Container Apps** | 0.5 vCPU, 1Gi | ExÃ©cution du pipeline (min=0, max=1) | ~0.01â‚¬/seconde active |
| **Cosmos DB PostgreSQL** | 1 vCore Burstable | Data warehouse distribuÃ© | ~50-70â‚¬/mois |
| **Log Analytics** | PerGB2018 | Monitoring et logs (<5GB) | Gratuit |
| **Container Apps Env** | - | Environnement pour Container Apps | Inclus |

**ğŸ’° CoÃ»t total estimÃ©** : ~60-80â‚¬/mois si actif 24/7  
**âš¡ Optimisation** : Utilisez `terraform destroy` quotidiennement pour Ã©conomiser ~70%
â”‚  â”‚  Image:      â”‚        â”‚                                 â”‚  â”‚
â”‚  â”‚  nyc-taxi-   â”‚        â”‚  Log Analytics Workspace        â”‚  â”‚
â”‚  â”‚  pipeline    â”‚        â”‚  - Application logs             â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚  - System metrics               â”‚  â”‚
â”‚                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ—‚ï¸ Structure du Projet

```
brief-terraform/
â”œâ”€â”€ .github/                       # CI/CD Workflows
â”‚   â”œâ”€â”€ workflows/
â”‚   â”‚   â”œâ”€â”€ ci.yml                # Validation Terraform + Docker build
â”‚   â”‚   â”œâ”€â”€ deploy.yml            # DÃ©ploiement automatique
â”‚   â”‚   â”œâ”€â”€ destroy.yml           # Destruction infrastructure
â”‚   â”‚   â”œâ”€â”€ pr-comment.yml        # Terraform plan sur PR
â”‚   â”‚   â””â”€â”€ README.md             # Documentation workflows
â”‚   â””â”€â”€ PULL_REQUEST_TEMPLATE.md
â”‚
â”œâ”€â”€ terraform/                     # ğŸ—ï¸ Infrastructure as Code
â”‚   â”œâ”€â”€ main.tf                   # Resource Group, random suffix
â”‚   â”œâ”€â”€ providers.tf              # Configuration Azure Provider
â”‚   â”œâ”€â”€ variables.tf              # DÃ©finition des variables
â”‚   â”œâ”€â”€ outputs.tf                # Outputs (URLs, noms, etc.)
â”‚   â”œâ”€â”€ terraform.tfvars          # âš ï¸ Vos valeurs (non committÃ©)
â”‚   â”œâ”€â”€ terraform.tfvars.example  # Template de configuration
â”‚   â”œâ”€â”€ storage.tf                # Storage Account + containers
â”‚   â”œâ”€â”€ acr.tf                    # Azure Container Registry
â”‚   â”œâ”€â”€ cosmosdb.tf               # Cosmos DB for PostgreSQL
â”‚   â”œâ”€â”€ log_analytics.tf          # Log Analytics Workspace
â”‚   â””â”€â”€ container_apps.tf         # Container Apps Environment + App
â”‚
â”œâ”€â”€ pipelines/                     # ğŸ Application Python (fournie)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ ingestion/
â”‚   â”‚   â””â”€â”€ download.py           # Pipeline 1: Download NYC data
â”‚   â”œâ”€â”€ staging/
â”‚   â”‚   â””â”€â”€ load_duckdb.py        # Pipeline 2: Load to PostgreSQL
â”‚   â””â”€â”€ transformation/
â”‚       â””â”€â”€ transform.py          # Pipeline 3: Star Schema
â”‚
â”œâ”€â”€ utils/                        # ğŸ› ï¸ Utilitaires (fournis)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ database.py              # Connexions PostgreSQL/DuckDB
â”‚   â”œâ”€â”€ download_helper.py       # Helper tÃ©lÃ©chargement + Azure
â”‚   â””â”€â”€ parquet_utils.py         # Gestion fichiers Parquet
â”‚
â”œâ”€â”€ sql/                          # ğŸ“ Scripts SQL (fournis)
â”‚   â”œâ”€â”€ init.sql                 # Initialisation
â”‚   â”œâ”€â”€ create_staging_table.sql # Table staging
â”‚   â”œâ”€â”€ truncate.sql             # Nettoyage
â”‚   â”œâ”€â”€ transformations.sql      # CrÃ©ation DIM/FACT
â”‚   â””â”€â”€ insert_to.sql            # Insertion donnÃ©es
â”‚
â”œâ”€â”€ Dockerfile                    # ğŸ³ Multi-stage build (fourni)
â”œâ”€â”€ docker-compose.yml            # Dev local (fourni)
â”œâ”€â”€ main.py                       # Point d'entrÃ©e (fourni)
â”œâ”€â”€ pyproject.toml                # DÃ©pendances Python
â”œâ”€â”€ Makefile                      # Commandes utiles
â”œâ”€â”€ .gitignore                    # Fichiers exclus de Git
â”œâ”€â”€ BRIEF.md                      # Cahier des charges
â”œâ”€â”€ SERVICE_PRINCIPAL_REQUEST.md  # Demande SP pour formateur
â””â”€â”€ README.md                     # ğŸ“– Ce fichier
```

## ğŸš€ PrÃ©requis

### ğŸ”§ Outils Requis

Avant de commencer, assurez-vous d'avoir installÃ© :

#### 1. **Azure CLI** (v2.50+)
```bash
# macOS
brew install azure-cli

# VÃ©rification
az --version

# Connexion Ã  Azure
az login

# VÃ©rifier la souscription active
az account show
```

#### 2. **Terraform** (v1.6.0+)
```bash
# macOS
brew tap hashicorp/tap
brew install hashicorp/tap/terraform

# VÃ©rification
terraform --version
```

#### 3. **Docker Desktop** (pour build d'image)
```bash
# macOS : https://www.docker.com/products/docker-desktop/

# VÃ©rification
docker --version
docker ps  # Doit retourner une liste vide (pas d'erreur)
```

#### 4. **Git** (pour versionning)
```bash
# macOS (prÃ©-installÃ©)
git --version
```

### ğŸ“‹ Comptes Requis

1. **Compte Azure**
   - Azure for Students (crÃ©dit gratuit) ou souscription valide
   - Droits **Contributor** sur un Resource Group

2. **Compte GitHub** (pour CI/CD - optionnel)
   - Repository public ou privÃ©
   - Secrets configurÃ©s pour GitHub Actions

### âœ… VÃ©rification Rapide

```bash
# Test que tous les outils sont installÃ©s
az --version && terraform --version && docker --version && git --version
```

Si toutes les commandes rÃ©ussissent, vous Ãªtes prÃªt ! ğŸ‰
## âš™ï¸ Configuration

### 1ï¸âƒ£ Cloner le Repository

```bash
git clone https://github.com/Flockyy/brief-terraform.git
cd brief-terraform
```

### 2ï¸âƒ£ Configurer les Variables Terraform

CrÃ©ez votre fichier de configuration Ã  partir du template :

```bash
cd terraform
cp terraform.tfvars.example terraform.tfvars
```

Ã‰ditez `terraform/terraform.tfvars` avec vos valeurs :

```hcl
# Azure subscription ID (obtenir avec : az account show --query id -o tsv)
azure_subscription_id = "votre-subscription-id"

# Configuration projet
project_name = "nyctaxi"
environment  = "dev"
location     = "francecentral"  # âš ï¸ Obligatoire pour le brief

# Configuration PostgreSQL
postgres_admin_username = "citus"
postgres_admin_password = "VotreMotDePasseSecurise123!"  # âš ï¸ Min 8 caractÃ¨res, pas de @

# Configuration ingestion donnÃ©es
start_date = "2024-01"  # Format YYYY-MM
end_date   = "2024-03"  # 3 mois de donnÃ©es recommandÃ©

# Votre IP publique (optionnel, pour accÃ¨s PostgreSQL)
# Obtenir avec : curl -4 ifconfig.me
allowed_ip_address = ""  # Ex: "45.81.84.9"
```

### 3ï¸âƒ£ Initialiser Terraform

```bash
cd terraform
terraform init
```

**Sortie attendue** :
```
Initializing the backend...
Initializing provider plugins...
- Installing hashicorp/azurerm v4.57.0...
- Installing hashicorp/random v3.8.0...

Terraform has been successfully initialized!
```

### 4ï¸âƒ£ Valider la Configuration

```bash
terraform validate
terraform fmt -check
```

Si tout est correct, passez au dÃ©ploiement ! ğŸš€
# Nom du projet
project_name = "nyctaxi"

# Environnement
environment = "dev"

# RÃ©gion Azure (obligatoire: francecentral)
location = "francecentral"

# Tags
tags = {
  Project     = "NYC Taxi Pipeline"
  ManagedBy   = "Terraform"
  Environment = "dev"
  Owner       = "VotreNom"
}

# Configuration des pipelines
start_date = "2025-01"  # Date de dÃ©but (YYYY-MM)
end_date   = "2025-02"  # Date de fin (YYYY-MM)

# Cosmos DB
cosmos_db_admin_username = "taxiadmin"
# cosmos_db_admin_password = null  # GÃ©nÃ©rÃ© automatiquement si null

# Container Apps
container_apps_cpu         = 0.5
container_apps_memory      = "1Gi"
container_apps_min_replicas = 0
container_apps_max_replicas = 1
```

### 2. Initialiser Terraform

```bash
cd terraform
terraform init
```

### 3. Valider la configuration

```bash
terraform validate
terraform plan
```

## ğŸ“¦ DÃ©ploiement

### Ã‰tape 1 : Planifier le DÃ©ploiement

VÃ©rifiez les ressources qui seront crÃ©Ã©es :

```bash
cd terraform
terraform plan
```

**ğŸ’¡ Conseil** : Examinez attentivement le plan pour comprendre ce qui va Ãªtre crÃ©Ã©.

Vous devriez voir **11 ressources** Ã  crÃ©er :
- 1x random_string (suffixe unique)
- 1x storage_account + 2x storage_container
- 1x container_registry
- 1x cosmosdb_postgresql_cluster + 2x firewall_rule
- 1x log_analytics_workspace
- 1x container_app_environment
- 1x container_app

### Ã‰tape 2 : Construire l'Image Docker

Avant de dÃ©ployer, construisez l'image Docker **pour AMD64** (pas ARM64) :

```bash
# Retour Ã  la racine du projet
cd ..

# Build multi-platform pour Azure (AMD64)
docker buildx build --platform linux/amd64 -t nyc-taxi-pipeline:latest --load .
```

**â±ï¸ DurÃ©e** : ~1-2 minutes

**Sortie attendue** :
```
[+] Building 12.9s (23/23) FINISHED
 => [internal] load build definition from Dockerfile
 => => transferring dockerfile: 797B
 => [internal] load .dockerignore
 ...
 => => naming to docker.io/library/nyc-taxi-pipeline:latest
```

### Ã‰tape 3 : DÃ©ployer l'Infrastructure

DÃ©ployez toutes les ressources Azure :

```bash
cd terraform
terraform apply
```

Tapez `yes` quand demandÃ©.

**â±ï¸ DurÃ©e** : ~12-15 minutes (Cosmos DB prend ~11 minutes)

**ğŸ“Š Progression** :
```
Terraform will perform the following actions:
  + create 11 resources

azurerm_log_analytics_workspace.main: Creating... [44s]
azurerm_container_registry.main: Creating... [23s]
azurerm_storage_account.main: Creating... [1m3s]
azurerm_cosmosdb_postgresql_cluster.main: Creating... [10m50s] â³ Long!
azurerm_container_app_environment.main: Creating... [48s]
azurerm_container_app.pipeline: Creating... [17s]

Apply complete! Resources: 11 added, 0 changed, 0 destroyed.
```

### Ã‰tape 4 : RÃ©cupÃ©rer les Informations de DÃ©ploiement

```bash
# Afficher tous les outputs
terraform output

# RÃ©cupÃ©rer l'URL ACR
terraform output -raw container_registry_login_server

# RÃ©cupÃ©rer le nom du Container App
terraform output -raw container_app_name
```

**Exemple d'outputs** :
```
container_registry_login_server = "acrnyctaxiw2t94joh.azurecr.io"
## ğŸ” Utilisation

### Consulter les Logs du Pipeline

Le Container App s'exÃ©cute automatiquement au dÃ©marrage. Consultez les logs :

```bash
# Obtenir le nom du Container App
CONTAINER_APP_NAME=$(cd terraform && terraform output -raw container_app_name)
RESOURCE_GROUP="fabgrallRG"

# Afficher les logs en temps rÃ©el
az containerapp logs show \
  --name $CONTAINER_APP_NAME \
  --resource-group $RESOURCE_GROUP \
  --follow

# Afficher les 50 derniÃ¨res lignes
az containerapp logs show \
  --name $CONTAINER_APP_NAME \
  --resource-group $RESOURCE_GROUP \
  --tail 50
```

**ğŸ“Š Logs attendus** :
```
10:38:10 | INFO | 3 fichiers Ã  tÃ©lÃ©charger
10:38:10 | INFO | Mode Azure activÃ©
10:38:10 | INFO | TÃ©lÃ©chargement de yellow_tripdata_2024-01.parquet...
10:38:12 | SUCCESS | Fichier tÃ©lÃ©chargÃ© avec succÃ¨s (47.65 MB)
10:38:14 | SUCCESS | Fichier uploadÃ© vers Azure : raw/yellow_tripdata_2024-01.parquet
10:38:14 | INFO | TÃ©lÃ©chargement de yellow_tripdata_2024-02.parquet...
10:38:16 | SUCCESS | Fichier tÃ©lÃ©chargÃ© avec succÃ¨s (48.02 MB)
10:38:18 | SUCCESS | Fichier uploadÃ© vers Azure : raw/yellow_tripdata_2024-02.parquet
10:38:18 | INFO | TÃ©lÃ©chargement de yellow_tripdata_2024-03.parquet...
10:38:20 | SUCCESS | Fichier tÃ©lÃ©chargÃ© avec succÃ¨s (57.30 MB)
10:38:23 | SUCCESS | Fichier uploadÃ© vers Azure : raw/yellow_tripdata_2024-03.parquet
âœ… Pipeline 1 (Download) terminÃ©
```

### VÃ©rifier les Fichiers dans le Storage

```bash
STORAGE_ACCOUNT=$(cd terraform && terraform output -raw storage_account_name)

# Lister les fichiers dans le container raw
az storage blob list \
  --container-name raw \
  --account-name $STORAGE_ACCOUNT \
  --output table \
  --auth-mode key \
  --account-key $(cd terraform && terraform output -raw storage_account_key)
```

**Sortie attendue** :
```
Name                             Blob Type    Length    Last Modified
yellow_tripdata_2024-01.parquet  BlockBlob    49961641  2026-01-16T10:38:31+00:00
yellow_tripdata_2024-02.parquet  BlockBlob    50349284  2026-01-16T10:38:33+00:00
yellow_tripdata_2024-03.parquet  BlockBlob    60078280  2026-01-16T10:38:36+00:00
```

### Se Connecter Ã  PostgreSQL

```bash
POSTGRES_HOST=$(cd terraform && terraform output -raw postgres_host)
POSTGRES_PASSWORD="VotreMotDePasseSecurise123!"  # Votre mot de passe

# Connexion avec psql
psql "postgresql://citus:$POSTGRES_PASSWORD@$POSTGRES_HOST:5432/citus?sslmode=require"

# Si psql n'est pas installÃ©, installez-le :
# brew install libpq
# brew link --force libpq
```

**RequÃªtes SQL utiles** :
```sql
-- Lister les tables
\dt

-- Compter les enregistrements dans staging
SELECT COUNT(*) FROM staging_taxi_trips;

-- VÃ©rifier les dimensions
SELECT COUNT(*) FROM dim_datetime;
SELECT COUNT(*) FROM dim_location;
SELECT COUNT(*) FROM dim_payment;
SELECT COUNT(*) FROM dim_vendor;

-- RequÃªte sur la table de faits
SELECT 
    COUNT(*) as total_trips,
    SUM(trip_distance) as total_distance,
    AVG(fare_amount) as avg_fare
FROM fact_trips;
```

### RedÃ©marrer le Pipeline

Si vous souhaitez rÃ©exÃ©cuter le pipeline :

```bash
# Via Azure CLI
az containerapp revision restart \
  --name $CONTAINER_APP_NAME \
  --resource-group $RESOURCE_GROUP
```
storage_account_name = "stnyctaxiw2t94joh"
container_app_name = "ca-nyctaxi-pipeline-dev"
```

### Ã‰tape 5 : Pousser l'Image Docker vers ACR

Maintenant que l'ACR est crÃ©Ã©, poussez votre image :

```bash
# Retour Ã  la racine
cd ..

# Se connecter Ã  ACR
ACR_NAME=$(cd terraform && terraform output -raw container_registry_name)
az acr login --name $ACR_NAME

# RÃ©cupÃ©rer l'URL ACR
ACR_URL=$(cd terraform && terraform output -raw container_registry_login_server)

# Taguer l'image
docker tag nyc-taxi-pipeline:latest $ACR_URL/nyc-taxi-pipeline:latest

# Pousser vers ACR
docker push $ACR_URL/nyc-taxi-pipeline:latest
```

**Sortie attendue** :
```
Login Succeeded
The push refers to repository [acrnyctaxiw2t94joh.azurecr.io/nyc-taxi-pipeline]
...
latest: digest: sha256:fed289d61de5db3b... size: 2618
```

### Ã‰tape 6 : VÃ©rifier le DÃ©ploiement

VÃ©rifiez que toutes les ressources sont dÃ©ployÃ©es :

```bash
# Lister toutes les ressources
az resource list --resource-group fabgrallRG --output table

# VÃ©rifier l'image dans ACR
az acr repository list --name $ACR_NAME

# VÃ©rifier le Container App
az containerapp list --resource-group fabgrallRG --output table
```

âœ… **DÃ©ploiement complet !** L'infrastructure est maintenant opÃ©rationnelle.

### Ã‰tape 2 : Build et Push de l'image Docker

```bash
# RÃ©cupÃ©rer le nom de l'ACR
ACR_NAME=$(terraform output -raw acr_name)
ACR_URL=$(terraform output -raw acr_login_server)

# Se connecter Ã  ACR
az acr login --name $ACR_NAME

# Revenir Ã  la racine du projet
cd ..

# Builder l'image Docker
docker build -t nyc-taxi-pipeline:latest .

# Tagger l'image pour ACR
docker tag nyc-taxi-pipeline:latest $ACR_URL/nyc-taxi-pipeline:latest

# Pousser vers ACR
docker push $ACR_URL/nyc-taxi-pipeline:latest

# VÃ©rifier que l'image est bien dans ACR
az acr repository show-tags --name $ACR_NAME --repository nyc-taxi-pipeline
```

### Ã‰tape 3 : DÃ©ployer l'infrastructure complÃ¨te

```bash
# Revenir dans terraform/
cd terraform

# DÃ©ployer toute l'infrastructure
terraform apply
```

**â±ï¸ DurÃ©e estimÃ©e** : 5-10 minutes (Cosmos DB prend du temps Ã  provisionner)

### Ã‰tape 4 : VÃ©rifier le dÃ©ploiement

```bash
# Lister toutes les ressources crÃ©Ã©es
az resource list --resource-group rg-nyctaxi-dev --output table

# VÃ©rifier le Container App
az containerapp list --resource-group rg-nyctaxi-dev --output table
```

## ğŸ“Š Utilisation

### Voir les logs du pipeline

```bash
# Suivre les logs en temps rÃ©el
az containerapp logs show \
  --name ca-nyctaxi-pipeline-dev \
  --resource-group rg-nyctaxi-dev \
  --follow

# Voir les derniers logs
az containerapp logs show \
  --name ca-nyctaxi-pipeline-dev \
  --resource-group rg-nyctaxi-dev \
  --tail 100
```

### Se connecter Ã  la base de donnÃ©es

```bash
# RÃ©cupÃ©rer la connection string
terraform output cosmos_db_connection_string

# Se connecter avec psql (si votre IP est autorisÃ©e)
psql "postgresql://taxiadmin:PASSWORD@cosmos-nyctaxi-dev-XXXXX.postgres.cosmos.azure.com:5432/citus?sslmode=require"
```

### RequÃªtes SQL pour vÃ©rifier les donnÃ©es

```sql
-- VÃ©rifier la table staging
SELECT COUNT(*) FROM staging_taxi_trips;

-- VÃ©rifier les tables de dimensions
SELECT COUNT(*) FROM dim_datetime;
SELECT COUNT(*) FROM dim_location;
SELECT COUNT(*) FROM dim_payment;
SELECT COUNT(*) FROM dim_vendor;

-- VÃ©rifier la table de faits
SELECT COUNT(*) FROM fact_trips;

-- Exemple : Revenus par jour de la semaine
SELECT
    d.jour_semaine_nom,
    COUNT(*) as nombre_courses,
    AVG(f.montant_total) as revenu_moyen
FROM fact_trips f
JOIN dim_datetime d ON f.pickup_datetime_key = d.datetime_key
GROUP BY d.jour_semaine_nom
ORDER BY nombre_courses DESC;
```

## ğŸ”§ Troubleshooting

Ce projet Ã©tant rÃ©alisÃ© dans un environnement de formation, plusieurs problÃ¨mes ont Ã©tÃ© rencontrÃ©s. Voici les solutions documentÃ©es :

### 1. âŒ Erreur : Service Principal Permissions Insuffisantes

**ProblÃ¨me** :
```
AuthorizationFailed: The client 'xxx@domain.com' with object id 'xxx' does not have 
authorization to perform action 'Microsoft.Authorization/roleAssignments/write' over scope 
'/subscriptions/5e2150ec-ee17-4fa2-8714-825c2fb7d22a'
```

**Contexte** : Tentative de crÃ©ation automatique d'un Service Principal pour GitHub Actions dans un environnement de formation.

**Solution** :
1. **Option A** : Demander au formateur de crÃ©er le Service Principal
   ```bash
   az ad sp create-for-rbac \
     --name "sp-nyctaxi-cicd" \
     --role contributor \
     --scopes /subscriptions/5e2150ec-ee17-4fa2-8714-825c2fb7d22a \
     --sdk-auth
   ```
   
2. **Option B** : Utiliser les workflows CI/CD avec des secrets manuels (voir `.github/workflows/README.md`)

3. **Option C** : DÃ©ployer manuellement avec Terraform (ce qui a Ã©tÃ© fait pour ce projet)

**LeÃ§on** : Les environnements de formation ont souvent des restrictions IAM. Toujours vÃ©rifier les permissions avant d'implÃ©menter des pipelines automatisÃ©s.

---

### 2. âŒ Erreur : Architecture Docker Incompatible

**ProblÃ¨me** :
```
Error: creating Container App: containerappsjob.ContainerAppsAPIClient#CreateOrUpdate: 
Failure responding to request: StatusCode=400
Code="InvalidTemplateDeployment"
Message="The image OS/Arch must be 'linux/amd64' but found 'linux/arm64'"
```

**Contexte** : Build Docker sur MacBook avec processeur Apple Silicon (ARM64), mais Azure Container Apps nÃ©cessite AMD64.

**Solution** :
```bash
# Build multi-plateforme avec BuildX
docker buildx build \
  --platform linux/amd64 \
  --tag ${ACR_NAME}.azurecr.io/nyc-taxi-pipeline:latest \
  --load \
  .

# Pousser vers ACR
docker push ${ACR_NAME}.azurecr.io/nyc-taxi-pipeline:latest
```

**VÃ©rification** :
```bash
# Inspecter l'image
docker inspect ${ACR_NAME}.azurecr.io/nyc-taxi-pipeline:latest | grep -i arch
# Doit afficher: "Architecture": "amd64"
```

**LeÃ§on** : Toujours builder les images Docker pour l'architecture de destination. Azure Container Apps requiert `linux/amd64`.

---

### 3. âŒ Erreur : PostgreSQL Connection String Parsing

**ProblÃ¨me** :
```
ERROR | 10:38:40 | Erreur Pipeline 2: Connection string is invalid or not a URI
could not translate host name "ss@c-cosmos-nyctaxi-dev.j3gmskci73hpbt.postgres.cosmos.azure.com" 
to address: nodename nor servname provided, or not known
```

**Contexte** : Le mot de passe PostgreSQL contient le caractÃ¨re `@` qui casse le parsing de l'URL de connexion.

**Mot de passe problÃ©matique** : `NycTaxi2026!SecureP@ss`

**Solution 1 - URL Encoding** (recommandÃ©) :
```python
# Dans utils/database.py
from urllib.parse import quote_plus

password_encoded = quote_plus(os.getenv("POSTGRES_PASSWORD"))
connection_string = (
    f"postgresql://citus:{password_encoded}@"
    f"{os.getenv('POSTGRES_HOST')}:5432/citus?sslmode=require"
)
```

**Solution 2 - Changer le mot de passe** (Ã©viter les caractÃ¨res spÃ©ciaux) :
```hcl
# Dans terraform/terraform.tfvars
postgres_admin_password = "NycTaxi2026SecurePass"  # Sans @
```

**Solution 3 - Utiliser psycopg2 directement** :
```python
import psycopg2
conn = psycopg2.connect(
    host=os.getenv("POSTGRES_HOST"),
    port=5432,
    user="citus",
    password=os.getenv("POSTGRES_PASSWORD"),  # Pas de parsing URL
    dbname="citus",
    sslmode="require"
)
```

**LeÃ§on** : Ã‰viter les caractÃ¨res spÃ©ciaux (`@`, `:`, `/`, `?`) dans les mots de passe utilisÃ©s dans des URIs de connexion, ou utiliser l'URL encoding.

---

### 4. âŒ Erreur : Container App Already Exists

**ProblÃ¨me** :
```
Error: A resource with the ID "/subscriptions/.../resourceGroups/fabgrallRG/providers/
Microsoft.App/containerApps/ca-nyctaxi-pipeline-dev" already exists
```

**Contexte** : AprÃ¨s un dÃ©ploiement Ã©chouÃ©, le Container App existe dans Azure mais pas dans le state Terraform.

**Solution** :
```bash
# Option A : Importer la ressource existante
cd terraform
terraform import azurerm_container_app.pipeline \
  /subscriptions/5e2150ec-ee17-4fa2-8714-825c2fb7d22a/resourceGroups/fabgrallRG/providers/Microsoft.App/containerApps/ca-nyctaxi-pipeline-dev

# Option B : Supprimer et recrÃ©er
az containerapp delete \
  --name ca-nyctaxi-pipeline-dev \
  --resource-group fabgrallRG \
  --yes

terraform apply
```

**LeÃ§on** : En cas d'Ã©chec de dÃ©ploiement Terraform, vÃ©rifier l'Ã©tat rÃ©el des ressources Azure avant de rÃ©essayer. PrÃ©fÃ©rer l'import Terraform Ã  la suppression manuelle.

---

### 5. âš ï¸ Warning : Microsoft.App Provider Non EnregistrÃ©

**ProblÃ¨me** :
```
Error: checking for presence of existing Container Apps Managed Environment: 
the Resource Provider "Microsoft.App" is not registered in Subscription "5e2150ec..."
```

**Solution** :
```bash
# Enregistrer le provider
az provider register --namespace Microsoft.App

# VÃ©rifier l'enregistrement (peut prendre 2-5 minutes)
az provider show --namespace Microsoft.App --query "registrationState"
# Doit retourner: "Registered"

# Attendre que le statut soit "Registered"
az provider show --namespace Microsoft.App --query "registrationState" --output tsv
```

**Puis dÃ©commenter dans `terraform/container_apps.tf`** :
```bash
# Relancer le plan Terraform
cd terraform
terraform plan
terraform apply
```

**LeÃ§on** : Toujours vÃ©rifier que les Resource Providers Azure nÃ©cessaires sont enregistrÃ©s avant de dÃ©ployer des ressources.

---

### 6. ğŸ› Diagnostic : Logs Vides ou Incomplets

**ProblÃ¨me** : Le Container App tourne mais aucun log n'apparaÃ®t.

**Solution** :
```bash
# VÃ©rifier le statut du Container App
az containerapp show \
  --name ca-nyctaxi-pipeline-dev \
  --resource-group fabgrallRG \
  --query "properties.runningStatus"

# VÃ©rifier les revisions
az containerapp revision list \
  --name ca-nyctaxi-pipeline-dev \
  --resource-group fabgrallRG \
  --output table

# Consulter Log Analytics directement
az monitor log-analytics query \
  --workspace $(cd terraform && terraform output -raw log_analytics_workspace_id) \
  --analytics-query "ContainerAppConsoleLogs_CL | order by TimeGenerated desc | limit 100"
```

---

### 7. âŒ Erreur : "MANIFEST_UNKNOWN" dans ACR

**ProblÃ¨me** :
```
Error: MANIFEST_UNKNOWN: manifest tagged by 'latest' is not found
```

**Cause** : L'image Docker n'a pas Ã©tÃ© poussÃ©e vers ACR avant `terraform apply`.

**Solution** :
```bash
# VÃ©rifier les images dans ACR
az acr repository list --name $ACR_NAME

# Pusher l'image si manquante
docker push ${ACR_URL}/nyc-taxi-pipeline:latest

# RÃ©essayer le dÃ©ploiement
terraform apply
```

---

### 8. ğŸ’° CoÃ»ts Inattendus

**ProblÃ¨me** : Les ressources Azure gÃ©nÃ¨rent des coÃ»ts mÃªme quand inutilisÃ©es.

**Solution** :
```bash
# ArrÃªter le Container App (min_replicas=0)
az containerapp update \
  --name ca-nyctaxi-pipeline-dev \
  --resource-group fabgrallRG \
  --min-replicas 0 \
  --max-replicas 0

# Ou dÃ©truire complÃ¨tement l'infrastructure
cd terraform
terraform destroy --auto-approve
```

**Configuration optimale** (dÃ©jÃ  dans `container_apps.tf`) :
```hcl
scale {
  min_replicas = 0  # Pas de coÃ»t quand inactif
  max_replicas = 1
}
```

**LeÃ§on** : Utiliser `min_replicas=0` pour les workloads job-like qui s'exÃ©cutent ponctuellement. Toujours dÃ©truire les ressources de dev/test aprÃ¨s utilisation.

---

### ğŸ“š Ressources Utiles pour le Troubleshooting

- [Azure Container Apps Documentation](https://learn.microsoft.com/en-us/azure/container-apps/)
- [Terraform Azure Provider Issues](https://github.com/hashicorp/terraform-provider-azurerm/issues)
- [DuckDB PostgreSQL Extension](https://duckdb.org/docs/extensions/postgres)
- [Azure Cosmos DB for PostgreSQL Docs](https://learn.microsoft.com/en-us/azure/cosmos-db/postgresql/)

## ğŸ’° Gestion des CoÃ»ts

### ğŸ’¸ Estimation des CoÃ»ts Mensuels

| Service | Configuration | CoÃ»t mensuel estimÃ© | Notes |
|---------|--------------|---------------------|-------|
| **Storage Account** | LRS, <1GB de donnÃ©es | ~0.02â‚¬/mois | NÃ©gligeable |
| **Container Registry** | Basic tier | ~5â‚¬/mois | Fixe |
| **Container Apps** | 0.5 vCPU, 1Gi RAM, min_replicas=0 | ~0.01â‚¬/s actif | FacturÃ© Ã  la seconde |
| **Cosmos DB for PostgreSQL** | 1 vCore Burstable | ~50-70â‚¬/mois | CoÃ»t principal |
| **Log Analytics** | <5GB/mois | Gratuit | Inclus dans l'offre |
| **RÃ©seau** | Transfert de donnÃ©es | <1â‚¬/mois | Minimal pour ce projet |

**ğŸ’¡ Total estimÃ©** : **~60-80â‚¬/mois** si actif 24/7

**âš ï¸ Attention** : Le coÃ»t principal provient du **Cosmos DB for PostgreSQL** qui est facturÃ© Ã  l'heure, mÃªme quand la base est inactive.

### ğŸ¯ StratÃ©gies d'Optimisation des CoÃ»ts

#### StratÃ©gie 1 : Destruction Quotidienne (RecommandÃ©e pour Dev)

```bash
# En fin de journÃ©e
cd terraform
terraform destroy --auto-approve

# Le lendemain matin
terraform apply --auto-approve
```

**âœ… Ã‰conomie** : ~70% des coÃ»ts (Cosmos DB facturÃ© uniquement durant les heures actives)  
**â±ï¸ Temps** : 10-12 minutes pour `terraform apply`

#### StratÃ©gie 2 : Weekend Automation avec Cron

```bash
# Ajouter dans crontab (crontab -e)
# DÃ©truire le vendredi soir Ã  20h
0 20 * * 5 cd /chemin/vers/brief-terraform/terraform && terraform destroy --auto-approve

# RecrÃ©er le lundi matin Ã  8h
0 8 * * 1 cd /chemin/vers/brief-terraform/terraform && terraform apply --auto-approve
```

**âœ… Ã‰conomie** : ~30% des coÃ»ts (pas de facturation durant les weekends)

#### StratÃ©gie 3 : Alertes Budget Azure

```bash
# CrÃ©er une alerte budget via Azure CLI
az consumption budget create \
  --resource-group fabgrallRG \
  --budget-name "brief-terraform-budget" \
  --amount 50 \
  --time-grain Monthly \
  --time-period "$(date +%Y-%m-01)" to "$(date -d '+1 month' +%Y-%m-01)"
```

Ou via le portail Azure :
1. **Azure Portal** â†’ **Cost Management + Billing**
2. **Budgets** â†’ **+ Add**
3. DÃ©finir limite : **50â‚¬/mois**
4. Configurer alerte email Ã  **80%** et **100%**

### ğŸ“Š Monitoring des CoÃ»ts en Temps RÃ©el

```bash
# Voir les coÃ»ts actuels du Resource Group
az consumption usage list \
  --start-date $(date -d '30 days ago' +%Y-%m-%d) \
  --end-date $(date +%Y-%m-%d) \
  | jq '[.[] | select(.name.value | contains("fabgrallRG"))] | map(.usageEnd + " - " + .name.value + ": " + (.pretaxCost | tostring))'

# Ou via le portail Azure
# Azure Portal â†’ Cost Management â†’ Cost Analysis â†’ Filter: fabgrallRG
```

### ğŸ›‘ ArrÃªt d'Urgence (Sans Destruction)

Si vous voulez garder les donnÃ©es mais arrÃªter la facturation :

```bash
# ArrÃªter le Container App (ne facture plus)
az containerapp update \
  --name ca-nyctaxi-pipeline-dev \
  --resource-group fabgrallRG \
  --min-replicas 0 \
  --max-replicas 0

# Note : Cosmos DB continue de facturer mÃªme arrÃªtÃ©
# Seule solution : terraform destroy
```

---

## ğŸ§¹ Nettoyage de l'Infrastructure

### Option 1 : Destruction ComplÃ¨te (RecommandÃ©e)

```bash
cd terraform

# DÃ©truire toutes les ressources
terraform destroy

# Confirmer avec 'yes' quand demandÃ©
```

**â±ï¸ DurÃ©e** : ~5-7 minutes

**ğŸ“‹ Sortie attendue** :
```
Plan: 0 to add, 0 to change, 11 to destroy.

azurerm_container_app.pipeline: Destroying... [5s]
azurerm_container_app_environment.main: Destroying... [45s]
azurerm_cosmosdb_postgresql_cluster.main: Destroying... [3m12s] â³
azurerm_container_registry.main: Destroying... [18s]
azurerm_storage_account.main: Destroying... [21s]
azurerm_log_analytics_workspace.main: Destroying... [9s]

Destroy complete! Resources: 11 destroyed.
```

### Option 2 : Destruction CiblÃ©e (Garder Certaines Ressources)

Si vous voulez garder le Storage Account avec les donnÃ©es :

```bash
# Retirer le Storage Account du state Terraform (ne sera plus gÃ©rÃ©)
terraform state rm azurerm_storage_account.main

# Puis dÃ©truire le reste
terraform destroy
```

### Option 3 : Destruction Auto-ApprouvÃ©e (Sans Confirmation)

```bash
# Utile pour scripts/automation
terraform destroy --auto-approve
```

âš ï¸ **Attention** : Cette commande ne demande pas de confirmation !

### VÃ©rification Post-Destruction

```bash
# VÃ©rifier qu'il ne reste aucune ressource
az resource list --resource-group fabgrallRG --output table

# Si la commande retourne des ressources, les supprimer manuellement
az group delete --name fabgrallRG --yes --no-wait
```

**Sortie attendue** (aucune ressource) :
```
Name    ResourceGroup    Location    Type    Status
------  ---------------  ----------  ------  --------
(vide)
```

### Nettoyage Local

```bash
# Supprimer le state Terraform local (si backend non distant)
cd terraform
rm -f terraform.tfstate terraform.tfstate.backup

# Supprimer les fichiers de lock
rm -f .terraform.lock.hcl

# Supprimer les providers tÃ©lÃ©chargÃ©s
rm -rf .terraform/

# Supprimer les images Docker locales
docker rmi nyc-taxi-pipeline:latest
docker rmi acrnyctaxiw2t94joh.azurecr.io/nyc-taxi-pipeline:latest

# Nettoyer les images Docker inutilisÃ©es
docker system prune -a
```

### VÃ©rification de la ReproductibilitÃ©

Pour s'assurer que le projet est bien reproductible :

```bash
# 1. DÃ©truire complÃ¨tement
terraform destroy --auto-approve

# 2. Nettoyer l'Ã©tat local
rm -f terraform.tfstate* .terraform.lock.hcl
rm -rf .terraform/

# 3. RÃ©initialiser Terraform
terraform init

# 4. RecrÃ©er l'infrastructure
terraform apply --auto-approve

# 5. VÃ©rifier que tout fonctionne
az containerapp logs show \
  --name ca-nyctaxi-pipeline-dev \
  --resource-group fabgrallRG \
  --tail 100
```

**âœ… SuccÃ¨s** si vous voyez les logs du pipeline s'exÃ©cuter correctement aprÃ¨s la recrÃ©ation.

---

## ğŸ“¸ Captures d'Ã‰cran

> **Note** : Ajoutez ici des captures d'Ã©cran de votre dÃ©ploiement Azure pour documentation

### Vue d'Ensemble des Ressources

![Azure Resources Overview](docs/screenshots/azure-resources-overview.png)

**Ã€ capturer** :
- Azure Portal â†’ Resource Group `fabgrallRG`
- Liste des 11 ressources dÃ©ployÃ©es avec leur statut

### Container Registry

![Azure Container Registry](docs/screenshots/acr-repositories.png)

**Ã€ capturer** :
- Azure Portal â†’ Container Registry `acrnyctaxiw2t94joh`
- Onglet **Repositories** montrant l'image `nyc-taxi-pipeline:latest`
- Tag et digest de l'image

### Storage Account - Fichiers Parquet

![Azure Storage Blobs](docs/screenshots/storage-raw-container.png)

**Ã€ capturer** :
- Azure Portal â†’ Storage Account â†’ Containers â†’ `raw`
- Les 3 fichiers Parquet tÃ©lÃ©chargÃ©s :
  - `yellow_tripdata_2024-01.parquet` (~50MB)
  - `yellow_tripdata_2024-02.parquet` (~50MB)
  - `yellow_tripdata_2024-03.parquet` (~60MB)

### Container App - Logs d'ExÃ©cution

![Container App Logs](docs/screenshots/container-app-logs.png)

**Ã€ capturer** :
- Azure Portal â†’ Container Apps â†’ `ca-nyctaxi-pipeline-dev`
- Onglet **Log stream** ou **Console logs**
- Logs montrant l'exÃ©cution du Pipeline 1 (Download) avec succÃ¨s

### Cosmos DB for PostgreSQL

![Cosmos DB Cluster](docs/screenshots/cosmos-db-overview.png)

**Ã€ capturer** :
- Azure Portal â†’ Cosmos DB for PostgreSQL â†’ `cosmos-nyctaxi-dev`
- Configuration : 1 vCore, BurstableMemoryOptimized
- Connection string hostname

### Log Analytics Workspace

![Log Analytics Queries](docs/screenshots/log-analytics-queries.png)

**Ã€ capturer** :
- Azure Portal â†’ Log Analytics â†’ Logs
- RequÃªte KQL sur `ContainerAppConsoleLogs_CL`
- RÃ©sultats montrant les logs du pipeline

### Terraform Apply - Sortie ComplÃ¨te

![Terraform Apply Output](docs/screenshots/terraform-apply-output.png)

**Ã€ capturer** :
- Terminal montrant la sortie de `terraform apply`
- Message final : `Apply complete! Resources: 11 added, 0 changed, 0 destroyed.`
- Liste des outputs Terraform

### CI/CD GitHub Actions (Bonus)

![GitHub Actions Workflows](docs/screenshots/github-actions-workflows.png)

**Ã€ capturer** :
- GitHub Repository â†’ Actions
- Les 4 workflows crÃ©Ã©s : CI, Deploy, Destroy, PR Comment
- Statut d'une exÃ©cution rÃ©ussie (si Service Principal configurÃ©)

---

## ğŸ¥ DÃ©monstration VidÃ©o (Bonus)

Si vous rÃ©alisez une vidÃ©o de dÃ©monstration, incluez :

1. **Introduction** (30s)
   - PrÃ©sentation du projet et objectifs
   - Architecture dÃ©ployÃ©e

2. **Configuration Terraform** (1-2 min)
   - Parcourir les fichiers `.tf`
   - Expliquer les variables et outputs

3. **DÃ©ploiement** (2-3 min)
   - ExÃ©cuter `terraform init`
   - ExÃ©cuter `terraform plan`
   - ExÃ©cuter `terraform apply`
   - Montrer la crÃ©ation des ressources dans Azure Portal

4. **VÃ©rification** (2-3 min)
   - Voir les logs du Container App
   - Afficher les fichiers dans le Storage Account
   - Se connecter Ã  PostgreSQL (si Load rÃ©ussi)
   - RequÃªter les donnÃ©es

5. **Troubleshooting** (1-2 min)
   - Montrer une erreur rencontrÃ©e
   - Expliquer la solution appliquÃ©e

6. **Nettoyage** (1 min)
   - ExÃ©cuter `terraform destroy`
   - VÃ©rifier la suppression des ressources

**ğŸ¬ Total** : 8-12 minutes

---

## ï¿½ Ressources et Documentation

### ğŸ“– Documentation Officielle

#### Terraform
- [Terraform Azure Provider](https://registry.terraform.io/providers/hashicorp/azurerm/latest/docs) - Documentation complÃ¨te du provider
- [Terraform Language](https://www.terraform.io/language) - Syntaxe HCL et concepts
- [Terraform Best Practices](https://www.terraform-best-practices.com/) - Bonnes pratiques

#### Azure Services
- [Azure Container Apps](https://learn.microsoft.com/azure/container-apps/) - Service de conteneurs serverless
- [Cosmos DB for PostgreSQL](https://learn.microsoft.com/azure/cosmos-db/postgresql/) - Base de donnÃ©es distribuÃ©e
- [Azure Container Registry](https://learn.microsoft.com/azure/container-registry/) - Registry privÃ© Docker
- [Azure Storage](https://learn.microsoft.com/azure/storage/) - Blob storage et data lake
- [Log Analytics](https://learn.microsoft.com/azure/azure-monitor/logs/) - Monitoring et logs

#### Outils de DÃ©veloppement
- [Azure CLI Reference](https://learn.microsoft.com/cli/azure/) - Commandes Azure CLI
- [Docker Documentation](https://docs.docker.com/) - Build et dÃ©ploiement
- [DuckDB](https://duckdb.org/docs/) - Base de donnÃ©es analytique

### ğŸ“ Tutoriels et Guides

- [Getting Started with Terraform on Azure](https://learn.microsoft.com/azure/developer/terraform/get-started-cloud-shell)
- [Deploy Container Apps with Terraform](https://learn.microsoft.com/azure/container-apps/terraform-deploy)
- [Terraform State Management](https://www.terraform.io/language/state)

### ğŸ› Ressources pour le Troubleshooting

- [Azure Status](https://status.azure.com/) - Statut des services Azure
- [Terraform Azure Provider Issues](https://github.com/hashicorp/terraform-provider-azurerm/issues)
- [Stack Overflow - Azure Tag](https://stackoverflow.com/questions/tagged/azure)
- [Reddit r/Terraform](https://www.reddit.com/r/Terraform/)

### ğŸ“Š DonnÃ©es NYC Taxi

- [NYC TLC Trip Record Data](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page) - Source officielle
- [Data Dictionary](https://www.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_yellow.pdf) - Description des colonnes

---

## ğŸ“ Concepts ClÃ©s Appris

### Infrastructure as Code (IaC)
âœ… DÃ©finir l'infrastructure en code dÃ©claratif  
âœ… Versioning et collaboration via Git  
âœ… ReproductibilitÃ© des dÃ©ploiements  
âœ… Gestion du state Terraform

### Azure Cloud Services
âœ… Provisionnement de ressources Azure  
âœ… Container Apps pour workloads serverless  
âœ… Azure Container Registry pour images privÃ©es  
âœ… Cosmos DB for PostgreSQL distribuÃ©  
âœ… Monitoring avec Log Analytics

### DevOps & CI/CD
âœ… Workflows GitHub Actions  
âœ… Automatisation des dÃ©ploiements  
âœ… Service Principal pour authentification  
âœ… Secrets management

### Data Engineering
âœ… ETL Pipeline (Extract, Transform, Load)  
âœ… ModÃ©lisation en Ã©toile (Star Schema)  
âœ… Optimisation des requÃªtes analytiques  
âœ… DuckDB pour traitement de donnÃ©es

### Docker & Conteneurisation
âœ… Multi-stage builds pour optimisation  
âœ… Multi-platform builds (ARM64 vs AMD64)  
âœ… Registry privÃ© et versioning d'images  
âœ… Configuration via variables d'environnement

---

## ğŸ¯ AmÃ©liorations Possibles

### Niveau 1 : Fondamentaux
- [ ] **Backend Terraform distant** : Stocker le state dans Azure Storage avec locking
- [ ] **Environnements multiples** : Dev, Staging, Production avec workspaces
- [ ] **Variables validation** : Ajouter des contraintes de validation Terraform
- [ ] **Pre-commit hooks** : Valider le code Terraform avant commit

### Niveau 2 : SÃ©curitÃ© & QualitÃ©
- [ ] **Azure Key Vault** : Stocker les secrets (passwords, connection strings)
- [ ] **Managed Identity** : Remplacer les credentials par identitÃ©s gÃ©rÃ©es
- [ ] **Network Security** : VNet, Private Endpoints, NSG
- [ ] **Terraform modules** : CrÃ©er des modules rÃ©utilisables
- [ ] **Terratest** : Tests d'infrastructure automatisÃ©s
- [ ] **tflint** : Linting du code Terraform

### Niveau 3 : Production Ready
- [ ] **High Availability** : Multi-region deployment
- [ ] **Disaster Recovery** : Backup automatique et restauration
- [ ] **Monitoring avancÃ©** : Application Insights, alertes proactives
- [ ] **Cost Management** : Tags, budgets, auto-scaling optimisÃ©
- [ ] **GitOps** : ArgoCD ou Flux pour dÃ©ploiement continu
- [ ] **Infrastructure Testing** : Tests de bout en bout dans pipeline

### Niveau 4 : Data Engineering
- [ ] **Apache Airflow** : Orchestration des pipelines
- [ ] **Data Quality** : Great Expectations pour validation
- [ ] **Incremental Loads** : Charger uniquement les nouvelles donnÃ©es
- [ ] **dbt (Data Build Tool)** : Transformations SQL versionnÃ©es
- [ ] **Data Catalog** : Documentation automatique du schÃ©ma
- [ ] **BI Dashboard** : Power BI ou Looker pour visualisation

---

## ğŸ“ Notes Techniques

### Choix Architecturaux

#### Pourquoi Container Apps ?
- **Serverless** : Facturation Ã  la seconde, pas de gestion de cluster
- **Scale to Zero** : `min_replicas=0` pour optimiser les coÃ»ts
- **IntÃ©gration native** : Log Analytics, ACR, secrets management
- **Job-like workload** : Parfait pour pipelines ponctuels

#### Pourquoi Cosmos DB for PostgreSQL ?
- **Compatible PostgreSQL** : Code SQL standard, extensions disponibles
- **DistribuÃ©** : PrÃ©parÃ© pour scale horizontal si besoin
- **Managed** : Backup, HA, patching automatiques
- **Burstable tier** : CoÃ»t optimisÃ© pour dev/test

#### Pourquoi DuckDB ?
- **Analytique** : OptimisÃ© pour OLAP, pas OLTP
- **Parquet natif** : Lecture performante des fichiers columnar
- **In-memory** : Traitement rapide pour volumes modÃ©rÃ©s
- **LÃ©ger** : Pas de serveur sÃ©parÃ© Ã  gÃ©rer

### Tables CrÃ©Ã©es dans PostgreSQL

#### Tables de Staging
```sql
CREATE TABLE staging_taxi_trips (
    id SERIAL PRIMARY KEY,
    vendorid INTEGER,
    pickup_datetime TIMESTAMP,
    dropoff_datetime TIMESTAMP,
    passenger_count INTEGER,
    trip_distance FLOAT,
    ratecodeid INTEGER,
    store_and_fwd_flag VARCHAR(1),
    pulocationid INTEGER,
    dolocationid INTEGER,
    payment_type INTEGER,
    fare_amount FLOAT,
    extra FLOAT,
    mta_tax FLOAT,
    tip_amount FLOAT,
    tolls_amount FLOAT,
    improvement_surcharge FLOAT,
    total_amount FLOAT,
    congestion_surcharge FLOAT,
    airport_fee FLOAT
);
```

#### Tables de Dimensions
```sql
-- Dimension temporelle
CREATE TABLE dim_datetime (
    datetime_key INTEGER PRIMARY KEY,
    date_complete TIMESTAMP,
    annee INTEGER,
    mois INTEGER,
    jour INTEGER,
    heure INTEGER,
    jour_semaine INTEGER,
    jour_semaine_nom VARCHAR(20),
    mois_nom VARCHAR(20),
    trimestre INTEGER
);

-- Dimension gÃ©ographique
CREATE TABLE dim_location (
    location_key INTEGER PRIMARY KEY,
    location_id INTEGER,
    zone_name VARCHAR(255)
);

-- Dimension paiement
CREATE TABLE dim_payment (
    payment_key INTEGER PRIMARY KEY,
    payment_type_id INTEGER,
    payment_type_name VARCHAR(50)
);

-- Dimension fournisseur
CREATE TABLE dim_vendor (
    vendor_key INTEGER PRIMARY KEY,
    vendor_id INTEGER,
    vendor_name VARCHAR(100)
);
```

#### Table de Faits
```sql
CREATE TABLE fact_trips (
    trip_key SERIAL PRIMARY KEY,
    pickup_datetime_key INTEGER REFERENCES dim_datetime(datetime_key),
    dropoff_datetime_key INTEGER REFERENCES dim_datetime(datetime_key),
    pickup_location_key INTEGER REFERENCES dim_location(location_key),
    dropoff_location_key INTEGER REFERENCES dim_location(location_key),
    payment_key INTEGER REFERENCES dim_payment(payment_key),
    vendor_key INTEGER REFERENCES dim_vendor(vendor_key),
    nombre_passagers INTEGER,
    distance_trajet FLOAT,
    duree_trajet_minutes FLOAT,
    montant_course FLOAT,
    montant_extra FLOAT,
    montant_pourboire FLOAT,
    montant_peage FLOAT,
    montant_total FLOAT
);
```

### RequÃªtes Analytiques Exemples

```sql
-- Top 10 des zones les plus lucratives
SELECT 
    l.zone_name,
    COUNT(*) as nb_courses,
    ROUND(AVG(f.montant_total)::numeric, 2) as revenu_moyen,
    ROUND(SUM(f.montant_total)::numeric, 2) as revenu_total
FROM fact_trips f
JOIN dim_location l ON f.pickup_location_key = l.location_key
GROUP BY l.zone_name
ORDER BY revenu_total DESC
LIMIT 10;

-- Ã‰volution des revenus par jour de la semaine
SELECT 
    d.jour_semaine_nom,
    COUNT(*) as nb_courses,
    ROUND(AVG(f.montant_total)::numeric, 2) as revenu_moyen
FROM fact_trips f
JOIN dim_datetime d ON f.pickup_datetime_key = d.datetime_key
GROUP BY d.jour_semaine, d.jour_semaine_nom
ORDER BY d.jour_semaine;

-- Analyse des pourboires par type de paiement
SELECT 
    p.payment_type_name,
    COUNT(*) as nb_courses,
    ROUND(AVG(f.montant_pourboire)::numeric, 2) as pourboire_moyen,
    ROUND((AVG(f.montant_pourboire) / NULLIF(AVG(f.montant_course), 0) * 100)::numeric, 2) as pourcentage_pourboire
FROM fact_trips f
JOIN dim_payment p ON f.payment_key = p.payment_key
WHERE f.montant_course > 0
GROUP BY p.payment_type_name
ORDER BY pourboire_moyen DESC;
```

---

## âœ… Checklist Finale

### Avant de Soumettre le Projet

- [ ] **Code Terraform valide** : `terraform validate` passe
- [ ] **DÃ©ploiement testÃ©** : `terraform apply` rÃ©ussit sans erreurs
- [ ] **Logs vÃ©rifiÃ©s** : Pipeline Download s'exÃ©cute correctement
- [ ] **README complet** : Documentation claire et dÃ©taillÃ©e
- [ ] **Captures d'Ã©cran** : Au moins 5 screenshots Azure Portal
- [ ] **Troubleshooting documentÃ©** : Erreurs + solutions expliquÃ©es
- [ ] **ReproductibilitÃ©** : `terraform destroy` puis `apply` fonctionne
- [ ] **Code commentÃ©** : Fichiers `.tf` ont des commentaires explicatifs
- [ ] **Git propre** : Commits atomiques avec messages clairs
- [ ] **Secrets supprimÃ©s** : Pas de mots de passe dans Git
- [ ] **CoÃ»ts maÃ®trisÃ©s** : Infrastructure dÃ©truite aprÃ¨s tests

### Bonus CI/CD (Optionnel)

- [ ] **Workflows crÃ©Ã©s** : 4 workflows GitHub Actions
- [ ] **Documentation workflows** : `.github/workflows/README.md` complet
- [ ] **Service Principal** : Demande formateur documentÃ©e
- [ ] **Secrets configurÃ©s** : GitHub secrets expliquÃ©s dans doc

### Bonus VidÃ©o (Optionnel)

- [ ] **Script prÃ©parÃ©** : Plan de la dÃ©mo
- [ ] **Enregistrement** : 8-12 minutes, qualitÃ© audio/vidÃ©o correcte
- [ ] **Upload** : YouTube, Loom, ou partage OneDrive
- [ ] **Lien dans README** : Section dÃ©mo avec lien vidÃ©o

---

## ğŸ“„ Licence & Auteur

**Projet** : Brief Terraform - NYC Taxi Data Pipeline  
**Contexte** : Formation DevOps - Infrastructure as Code  
**Technologies** : Terraform, Azure, Docker, Python, PostgreSQL, DuckDB

**Source des donnÃ©es** : [NYC Taxi & Limousine Commission (TLC)](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page)

---

## ğŸ†˜ Support & Contact

Pour toute question sur ce projet :

1. **Documentation** : Consultez d'abord ce README et les commentaires dans le code
2. **Troubleshooting** : Voir la section dÃ©diÃ©e pour les erreurs courantes
3. **Issues GitHub** : Ouvrir une issue sur le repository
4. **Formateur** : Contacter pour questions Azure/Service Principal

---

**ğŸ‰ Merci d'avoir consultÃ© ce projet !**

Si vous avez trouvÃ© ce README utile, n'hÃ©sitez pas Ã  â­ star le repository !
